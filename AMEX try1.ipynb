{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e4d5419",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import math\n",
    "import os\n",
    "import pyarrow.feather as feather\n",
    "from sklearn import preprocessing\n",
    "from colorama import Fore, Back, Style\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.impute import MissingIndicator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52ea116e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data=pd.read_feather(\"../Kaggle/AMEX/train_data.ftr\")\n",
    "data=pd.read_feather(\"../Kaggle/AMEX/test_data.ftr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bd834ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data0(dat):\n",
    "\n",
    "    #https://www.kaggle.com/code/cdeotte/xgboost-starter-0-793: pick up at most 2 from each sector\n",
    "    #create interactions\n",
    "    print(\"creating interactions\")\n",
    "    Varimp=[\"P_2\",\"D_39\",\"B_4\",\"B_3\",\"D_46\",\"R_1\",\"S_3\",\"P_3\"]\n",
    "    temp=dat.copy()\n",
    "    for i in range(7):\n",
    "        for j in range(i+1,8):\n",
    "            key=Varimp[i]+\"_\"+Varimp[j]\n",
    "            temp.loc[:,key]=dat[Varimp[i]]*dat[Varimp[j]]\n",
    "    del dat\n",
    "\n",
    "\n",
    "    #create t\n",
    "    print(\"creating t\")\n",
    "    temp[\"S_2\"]=pd.to_datetime(temp[\"S_2\"])\n",
    "    temp[\"t\"] = temp.groupby(\"customer_ID\")[\"S_2\"].apply(lambda g: g.max() - g)\n",
    "    temp = temp.drop('S_2', 1)\n",
    "    temp[\"t\"]=temp[\"t\"].dt.days\n",
    "\n",
    "    return temp\n",
    "\n",
    "\n",
    "def make_data1(temp):\n",
    "\n",
    "    #declare column names\n",
    "    cat_cols=['B_30', 'B_38', 'D_114', 'D_116', 'D_117', 'D_120', 'D_126', 'D_63', 'D_64', 'D_66', 'D_68']\n",
    "    num_cols=list(set(temp.columns) - set(cat_cols)-set([\"customer_ID\"]))\n",
    "\n",
    "\n",
    "    #create per-ID data\n",
    "    #numeric+category\n",
    "    print(\"creating last\")\n",
    "    temp2=temp.groupby(\"customer_ID\").ffill()\n",
    "    temp2[\"customer_ID\"]=temp[\"customer_ID\"]\n",
    "    last=temp2.groupby(\"customer_ID\").last()\n",
    "    last=last.add_suffix('_last')\n",
    "    del temp2\n",
    "\n",
    "    print(\"creating count\")\n",
    "    count=temp.groupby(temp.customer_ID)[\"t\"].count()\n",
    "    count=count.rename(\"count\")\n",
    "\n",
    "    output=pd.concat([count,last], axis=1)\n",
    "    del last\n",
    "\n",
    "    print(\"creating na_perc\")\n",
    "    na_perc=temp.drop('customer_ID', 1).isna().groupby(temp.customer_ID, sort=False).sum().div(count, axis='rows')\n",
    "    del count\n",
    "\n",
    "    na_perc=na_perc.add_suffix('_na_perc')\n",
    "    output=pd.concat([output, na_perc], axis=1)\n",
    "    del na_perc\n",
    "\n",
    "\n",
    "    #category\n",
    "    print(\"creating freq\")\n",
    "    def foo(x): m = pd.Series.mode(x); return m.values[0] if not m.empty else np.nan\n",
    "\n",
    "    freq=temp.groupby(\"customer_ID\")[cat_cols].agg(foo)\n",
    "    freq=freq.add_suffix('_freq')\n",
    "\n",
    "    output=pd.concat([output, freq], axis=1)\n",
    "    del freq\n",
    "\n",
    "    print(\"creating catchange\")\n",
    "    def change_cat(series): \n",
    "        bb=series.values\n",
    "        count=sum((1 for i,x in enumerate(bb[:-1]) if (x!= bb[i+1]) and pd.isnull(x)==False))\n",
    "        return count\n",
    "\n",
    "    catchange=temp.groupby(\"customer_ID\")[cat_cols].agg(change_cat)\n",
    "    catchange=catchange.add_suffix('_catchange')\n",
    "\n",
    "    output=pd.concat([output, catchange], axis=1)\n",
    "    del catchange\n",
    "\n",
    "\n",
    "    #numeric\n",
    "    print(\"creating max\")\n",
    "    max=temp.groupby(\"customer_ID\")[num_cols].apply(lambda g: g.max())\n",
    "    max=max.add_suffix('_max')\n",
    "    output=pd.concat([output, max], axis=1)\n",
    "    del max\n",
    "\n",
    "    print(\"creating min\")\n",
    "    min=temp.groupby(\"customer_ID\")[num_cols].apply(lambda g: g.min())\n",
    "    min=min.add_suffix('_min')\n",
    "    output=pd.concat([output, min], axis=1)\n",
    "    del min\n",
    "\n",
    "    print(\"creating maxmin\")\n",
    "    maxmin=temp.groupby(\"customer_ID\")[num_cols].apply(lambda g: (g.max()-g.min())/g.min())\n",
    "    maxmin=maxmin.add_suffix('_maxmin')\n",
    "    output=pd.concat([output, maxmin], axis=1)\n",
    "    del maxmin\n",
    "\n",
    "    print(\"creating mean\")\n",
    "    mean=temp.groupby(\"customer_ID\")[num_cols].apply(lambda g: g.mean())\n",
    "    mean=mean.add_suffix('_mean')\n",
    "    output=pd.concat([output, mean], axis=1)\n",
    "    del mean\n",
    "\n",
    "    print(\"creating sd\")\n",
    "    sd=temp.groupby(\"customer_ID\")[num_cols].apply(lambda g: np.std(g))\n",
    "    sd=sd.add_suffix('_sd')\n",
    "    output=pd.concat([output, sd], axis=1)\n",
    "    del sd\n",
    "\n",
    "    feather.write_feather(output, '../Kaggle/AMEX/output1.ftr')\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def make_data2(temp):\n",
    "\n",
    "    #declare column names\n",
    "    cat_cols=['B_30', 'B_38', 'D_114', 'D_116', 'D_117', 'D_120', 'D_126', 'D_63', 'D_64', 'D_66', 'D_68']\n",
    "    num_cols=list(set(temp.columns) - set(cat_cols)-set([\"customer_ID\"]))\n",
    "\n",
    "    #numeric - difference\n",
    "    print(\"creating dif\")\n",
    "    dif=temp.groupby(\"customer_ID\")[num_cols].ffill().diff()\n",
    "    dif=dif.div(dif[\"t\"], axis='rows')\n",
    "    dif[\"customer_ID\"]=temp[\"customer_ID\"].tolist()\n",
    "\n",
    "    print(\"creating maxdif\")\n",
    "    maxdif=dif.groupby(\"customer_ID\")[num_cols].apply(lambda g: g.max())\n",
    "    maxdif=maxdif.add_suffix('_maxdif')\n",
    "\n",
    "    print(\"creating mindif\")\n",
    "    mindif=dif.groupby(\"customer_ID\")[num_cols].apply(lambda g: g.min())\n",
    "    mindif=mindif.add_suffix('_mindif')\n",
    "    output=pd.concat([maxdif, mindif], axis=1)\n",
    "    del maxdif,mindif\n",
    "\n",
    "    print(\"creating maxmindif\")\n",
    "    maxmindif=dif.groupby(\"customer_ID\")[num_cols].apply(lambda g: (g.max()-g.min())/g.min())\n",
    "    maxmindif=maxmindif.add_suffix('_maxmindif')\n",
    "    output=pd.concat([output, maxmindif], axis=1)\n",
    "    del maxmindif,dif\n",
    "\n",
    "    feather.write_feather(output, '../Kaggle/AMEX/output2.ftr')\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def make_data3(output):\n",
    "\n",
    "    #add features\n",
    "    print(\"adding features\")\n",
    "    output[\"totalNA\"]=output.isna().sum(axis=1).tolist()\n",
    "    output[\"totalNA_count\"]=output[\"totalNA\"]*output[\"count\"]\n",
    "\n",
    "\n",
    "    #delete novariance\n",
    "    print(\"original shape: \",output.shape)\n",
    "    output=output.loc[:,(output != output.iloc[0]).any()]\n",
    "    \n",
    "    print(\"shape after deleting nonvariance: \",output.shape)\n",
    "\n",
    "    #replace inf to nan\n",
    "    output=output.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "    #delete all NAs\n",
    "    output=output.dropna(axis=1, how='all')\n",
    "    print(\"shape after deleting NAN: \",output.shape)\n",
    "\n",
    "\n",
    "    #median/mode imputation\n",
    "    cat_cols=['B_30', 'B_38', 'D_114', 'D_116', 'D_117', 'D_120', 'D_126', 'D_63', 'D_64', 'D_66', 'D_68']\n",
    "    cat_last=[s + \"_last\" for s in cat_cols]\n",
    "    cat_freq=[s + \"_freq\" for s in cat_cols]\n",
    "    cat=cat_freq + cat_last\n",
    "    num=list(set(output.columns) - set(cat))\n",
    "\n",
    "    output[cat]=output[cat].astype(str)\n",
    "\n",
    "    print(\"Imputing by mode\")\n",
    "    imputer = SimpleImputer(strategy='most_frequent')# strategy can also be mean or median \n",
    "    imputer.fit(output[cat])\n",
    "    imputer=imputer.transform(output[cat])\n",
    "    newout_cat=pd.DataFrame(imputer, columns=output[cat].columns)\n",
    "\n",
    "    imputer = SimpleImputer(missing_values=None,strategy='most_frequent')# strategy can also be mean or median \n",
    "    imputer.fit(newout_cat)\n",
    "    imputer=imputer.transform(newout_cat)\n",
    "    newout_cat=pd.DataFrame(imputer, columns=newout_cat.columns)\n",
    "\n",
    "    print(\"Imputing by mean\")\n",
    "    imputer = SimpleImputer(strategy='mean')# strategy can also be mean or median \n",
    "    imputer.fit(output[num])\n",
    "    imputer=imputer.transform(output[num])\n",
    "    newout_cont=pd.DataFrame(imputer, columns=output[num].columns)\n",
    "\n",
    "    output=pd.concat([newout_cat, newout_cont], axis=1)\n",
    "\n",
    "    del newout_cat,newout_cont\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "685d9d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating interactions\n",
      "creating t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n5/w7wbnl8956x5xtgwp11w9b2c0000gn/T/ipykernel_27334/2040686411.py:19: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  temp = temp.drop('S_2', 1)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7640eac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating interactions\n",
      "creating t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n5/w7wbnl8956x5xtgwp11w9b2c0000gn/T/ipykernel_29858/3276472079.py:19: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  temp = temp.drop('S_2', 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating last\n",
      "creating count\n",
      "creating na_perc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n5/w7wbnl8956x5xtgwp11w9b2c0000gn/T/ipykernel_29858/3276472079.py:49: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  na_perc=temp.drop('customer_ID', 1).isna().groupby(temp.customer_ID, sort=False).sum().div(count, axis='rows')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating freq\n",
      "creating catchange\n",
      "creating max\n",
      "creating min\n",
      "creating maxmin\n",
      "creating mean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rikuta/miniforge3/envs/env/lib/python3.8/site-packages/numpy/core/_methods.py:48: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating sd\n",
      "creating dif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n5/w7wbnl8956x5xtgwp11w9b2c0000gn/T/ipykernel_29858/3276472079.py:126: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dif[\"customer_ID\"]=temp[\"customer_ID\"].tolist()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating maxdif\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "temp=make_data0(data)\n",
    "del data\n",
    "\n",
    "output1=make_data1(temp)\n",
    "output2=make_data2(temp)\n",
    "del temp\n",
    "\n",
    "#reset kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89d424cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#continue\n",
    "output1=pd.read_feather(\"../Kaggle/AMEX/output1.ftr\")\n",
    "output2=pd.read_feather(\"../Kaggle/AMEX/output2.ftr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff8bd5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "output=pd.concat([output1, output2], axis=1)\n",
    "del output1, output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d70b2e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding features\n",
      "original shape:  (458913, 2107)\n",
      "shape after deleting nonvariance:  (458913, 2035)\n",
      "shape after deleting NAN:  (458913, 2033)\n",
      "Imputing by mode\n",
      "Imputing by mean\n"
     ]
    }
   ],
   "source": [
    "train_use=make_data3(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "876571f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_use.isna().sum().sum()\n",
    "#[var for var in train_use.columns if train_use[var].isnull().sum() > 0]\n",
    "del output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "38c56dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feather.write_feather(train_use, '../Kaggle/AMEX/train_use.ftr')\n",
    "feather.write_feather(train_use, '../Kaggle/AMEX/test_use.ftr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326a8709",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b63ff3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "9dbcc0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ensemble\n",
    "test=pd.read_feather(\"../Kaggle/AMEX/test_data.ftr\")\n",
    "sub1 = pd.read_csv('../Kaggle/AMEX/submission_ens.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "266db92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CatBoost prediction\n",
    "col=data_use.columns\n",
    "test_ID=test['customer_ID'].unique()\n",
    "pred_catboost= clf.predict_proba(test_use[col])[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "76c57c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub2= pd.DataFrame({'customer_ID':test_ID, 'prediction2':pred_catboost})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "99b3d578",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ensemble\n",
    "sub1 = pd.read_csv('../Kaggle/AMEX/submission_ens.csv')\n",
    "\n",
    "blend = pd.merge(sub1, sub2, how='inner', on='customer_ID')\n",
    "blend.prediction = (blend.prediction * 0.95 + blend.prediction2 * 0.05)\n",
    "blend[['customer_ID', 'prediction']].to_csv('../Kaggle/AMEX/0613submission2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "4da8eb4402250ad25264d8ad4ce1c325063698da828d20e26522c6fdb53f3b79"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
